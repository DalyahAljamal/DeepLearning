{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author : Dalyah\n",
    "#Modifications: 11-4-2018 till 13-4-2018 \n",
    "\n",
    "#Pkg.update(\"ImageView\")\n",
    "using ImageView\n",
    "using Plots\n",
    "using Knet;\n",
    "using Compat,GZip \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Random Data and Minibatching\n",
    "# Input img:128*128\n",
    "#Batch Size= 128\n",
    "\n",
    "xtrn= 0.1*rand(128,128,1,5000);\n",
    "ytrn= 0.1*rand(48, 5000);\n",
    "\n",
    "\n",
    "xtst= 0.1*rand(128,128,1,1000);\n",
    "ytst= 0.1*rand(48, 1000);\n",
    "\n",
    "Atype = gpu() >= 0 ? KnetArray{Float32} : Array{Float32}\n",
    "#Atype= Array{Float32}\n",
    "\n",
    "dtrn = minibatch(xtrn,ytrn,120; xtype=Atype, ytype=Atype); \n",
    "dtst = minibatch(xtst,ytst,120; xtype=Atype, ytype=Atype); \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Zip Files\n",
    "using InfoZIP\n",
    "using ZipFile\n",
    "\n",
    "#InfoZIP.unzip(\"Training.zip\", \"Data/\")\n",
    "#InfoZIP.unzip(\"Testing.zip\", \"Data/\")\n",
    "\n",
    "#They are already extracted on my AWS image: HandPosE_Dalyah_v6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Image Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imgDraft file\n",
    "\n",
    "using Images\n",
    "using Colors\n",
    "images = Any[]\n",
    "rootpath=\"imgDraft\" # should change based on path on Machine you work on\n",
    "arr1 = [\"1\",\"2\"]\n",
    "arr2 = [\"123\",\"321\"]\n",
    "for i =1:length(arr1)\n",
    "    for j=1:length(arr2)\n",
    "        path2 = string(rootpath,\"/\",arr1[i],\"/\",arr2[j])\n",
    "        x =readdir(path2) #save all img names in arr1[i]/arr2[j] in x var\n",
    "        for k=1:length(x)\n",
    "            path3 = string(path2,\"/\",x[k])\n",
    "            \n",
    "            img = load(path3)\n",
    "            #Transfer to gray scale\n",
    "            img2=Float64.(Gray.(img))\n",
    "            #imshow(img)\n",
    "            #imshow(img2)\n",
    "            println(typeof(img))\n",
    "            println(size(img2))\n",
    "            \n",
    "            #Resize img to (128,128)\n",
    "            sz=(128,128)\n",
    "            σ = map((o,n)->0.75*o/n, size(img), sz)\n",
    "            kern = KernelFactors.gaussian(σ)   # from ImageFiltering\n",
    "            img3 = imresize(imfilter(img, kern, NA()), sz)\n",
    "            println(size(img3))\n",
    "            #imshow(img3)\n",
    "            #Convert to array\n",
    "            #img3 = convert(Array{float64},img2) # Check Visualization Lab\n",
    "            push!(images,img2)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "println(\"Final\")\n",
    "println(typeof(images))\n",
    "for x in images\n",
    "    println(size(x))\n",
    "    println(typeof(x))\n",
    "end\n",
    "println(length(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Training and Testing img labels\n",
    "\n",
    "#HOW THE DATA IS ORGANIZED\n",
    "\n",
    "#Each line is corresponding to one image.\n",
    "#Each line has 16x3 numbers, which indicates (x, y, z) of 16 joint locations. Note that these are joint CENTRE locations.\n",
    "#Note that (x, y) are in pixels and z is in mm.\n",
    "#The order of 16 joints is Palm, Thumb root, Thumb mid, Thumb tip,\n",
    "#Index root, Index mid, Index tip, Middle root, Middle mid, Middle tip, Ring root,\n",
    "#Ring mid, Ring tip, Pinky root, Pinky mid, Pinky tip.\n",
    "\n",
    "function read_labels(label_path)\n",
    "    labels=Any[]\n",
    "    open(label_path) do f\n",
    "         # loop through lines in file (images)\n",
    "            #loop through all words in a line (joint locations)\n",
    "                #skip first word\n",
    "                #stack all joint locations on top of each other\n",
    "                #return imgjoints vector(48,1) or (49, 1) as first element is the name of img\n",
    "            #horizantally concatanate imgjoints into labels matrix (48, #lines)\n",
    "        \n",
    "        for ln in eachline(f)\n",
    "            img_joints= Any[]\n",
    "            word= split(ln)\n",
    "            for i in 1:49\n",
    "                push!(img_joints, word[i])\n",
    "            end\n",
    "            #println(summary(img_joints))\n",
    "\n",
    "            if length(labels) ==0\n",
    "                labels=img_joints\n",
    "                #println(labels)\n",
    "            else\n",
    "                labels= hcat(labels, img_joints)\n",
    "            end\n",
    "        end\n",
    "        println(\"labels Dimentions\")\n",
    "        println(summary(labels))\n",
    "        println(length(labels))\n",
    "        println(labels[1,2])\n",
    "    end\n",
    "    return labels\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labelpath= \"Data/Training/labels.txt\"\n",
    "tst1_labelpath= \"Data/Testing/test_seq_1.txt\"\n",
    "tst2_labelpath= \"Data/Testing/test_seq_2.txt\"\n",
    "\n",
    "trn_labels= read_labels(trn_labelpath) # (49, )\n",
    "tst1_labels= read_labels(tst1_labelpath) # (49, )\n",
    "tst2_labels= read_labels(tst2_labelpath) # (49, )\n",
    "\n",
    "#The first label should be reomved to keep labels size (48, )\n",
    "\n",
    "println(map(summary,(trn_labels, tst1_labels, tst2_labels)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 Samples for the training , 4 is minibatch size to make sure the model is working fine \n",
    "#next assignment I will Train the model on the whole dataset\n",
    "\n",
    "xtrn= images\n",
    "ytrn= 0.1*rand(48, 8);\n",
    "\n",
    "\n",
    "Atype = gpu() >= 0 ? KnetArray{Float32} : Array{Float32}\n",
    "#Atype= Array{Float32}\n",
    "\n",
    "dtrn = minibatch(xtrn,ytrn,4; xtype=Atype, ytype=Atype); \n",
    "#dtst = minibatch(xtst,ytst,120; xtype=Atype, ytype=Atype); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of the REAL Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Diemtionalities\n",
    "\n",
    "#Desired Dim for (xtrn, ytrn, xtst, ytst)\n",
    "#(\"128×128×1×60000 Array{Float32,4}\", \"60000-element Array{UInt8,1}\",\n",
    "#\"128×128×1×10000 Array{Float32,4}\", \"10000-element Array{UInt8,1}\")\n",
    "\n",
    "println(map(summary,(xtrn,ytrn,xtst,ytst)))\n",
    "println(\"Num of MiniBatches\")\n",
    "println(length(dtrn))# Return number of MiniBatches size\n",
    "\n",
    "println(\"xtst\")\n",
    "for x in xtst\n",
    "    println(size(x))\n",
    "    println(summary(x))\n",
    "    println(typeof(x))\n",
    "    break;\n",
    "    #println(size(y)) \n",
    "end\n",
    "println(\"dtst\")\n",
    "for (x, y) in dtst\n",
    "    println(size(x)) \n",
    "    println(size(y)) \n",
    "end\n",
    "\n",
    "println(\"xtrn\")\n",
    "for x in xtrn\n",
    "    println(size(x)) \n",
    "    #println(size(y)) \n",
    "end\n",
    "println(\"dtrn\")\n",
    "for (x, y) in dtrn\n",
    "    println(size(x)) \n",
    "    println(size(y)) \n",
    "end\n",
    "\n",
    "#to return Dimentionality of each Minibatch\n",
    "println(\"Dim of first MiniBtch\")\n",
    "println(summary(dtrn))\n",
    "println(summary(dtrn))\n",
    "#(x, y) = first(dtrn);\n",
    "println(\"hh\")\n",
    "println(dtrn)\n",
    "println(xtrn)\n",
    "println(summary(y))\n",
    "\n",
    "#for (x, y) in dtrn\n",
    " #   \n",
    "#end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model\n",
    "\n",
    "1. Predict Function\n",
    "2. Loss Function\n",
    "3. Loss Gradient\n",
    "4. Prameter Intialization\n",
    "5. Trian Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyber Parameters\n",
    "\n",
    "Batch size: 128\n",
    "\n",
    "Momentum: 0.9\n",
    "\n",
    "Weight decay: 0.001\n",
    "\n",
    "Learning  rate: 0.01\n",
    "\n",
    "Epoch number: 100\n",
    "\n",
    "PCA Components: 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Functions\n",
    "\n",
    "# NLL Loss\n",
    "#loss(w,x,ygold) = nll(predict(w,x),ygold)\n",
    "\n",
    "#Mean Loss\n",
    "#loss(w,x,y)= mean(abs2,y-predict(w,x))\n",
    "function loss(w,x,y)\n",
    "    #y= convert(Array{Float32,2},y)\n",
    "    #y= convert(Knet.KnetArray{Float32,4},y)\n",
    "    return mean(abs2,y-predict(w,x))\n",
    "end\n",
    "\n",
    "#Huber Loss\n",
    "function huber_loss(w, x, y ; e=0.4)\n",
    "    ypred=predict(w,x)\n",
    "    N= size(y,1)\n",
    "    E= ill(e, N)\n",
    "    com=abs(y - ypred) .<= E\n",
    "    \n",
    "    out = true\n",
    "    for i in 1:length(s)\n",
    "        if  s[i] != true\n",
    "            out=false\n",
    "        end\n",
    "    end\n",
    "    if out\n",
    "        lo= 0.5* (y- ypred).^2\n",
    "    else\n",
    "        lo=e* abs(y - ypred) - 0.5 * (E .^2)\n",
    "        \n",
    "    end\n",
    "    return lo\n",
    "end\n",
    "\n",
    "#Gradient Loss\n",
    "lossgradient = grad(loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv 8(5*5) , Max Pool (4*4), Conv 8(5*5), Max Pool (2*2), Conv 8(3*3), 2 FC (1024),droupout, PCA (30), FC(48)\n",
    "function predict(w,x)\n",
    "    #win=[4,0,2]\n",
    "    #x= map(Atype,x)\n",
    "    #n=length(w)-8\n",
    "    #for i=1:2:n # we are jumping 2 steps since alwase we have w then b, then w  then b....\n",
    "     #   x = pool(relu.(conv4(w[i],x) .+ w[i+1]); window=win[i]) \n",
    "    #end\n",
    "    #i=n+1\n",
    "    #x= relu.(conv4(w[i],x) .+ w[i+1])\n",
    "    #for i=n+3:2:length(w)-2 # Fully connected layers\n",
    "    #    x = relu.(w[i]*mat(x) .+ w[i+1])\n",
    "    #end\n",
    "    # Add PCA layer later\n",
    "    #print(size( w[end-1]*mat(x) .+ w[end]  ))\n",
    "    #return w[end-1]*mat(x) .+ w[end]\n",
    "    \n",
    "    #First Conv Layer\n",
    "    x = pool(relu.(conv4(w[1],x) .+ w[2]); window=4) \n",
    "    \n",
    "    #Second Conv Layer\n",
    "    x = pool(relu.(conv4(w[3],x) .+ w[4]); window=2) \n",
    "    \n",
    "    #Third Conv Layer\n",
    "    x = relu.(conv4(w[5],x) .+ w[6])\n",
    "    \n",
    "    #FC 1\n",
    "    x = relu.(w[7]*mat(x) .+ w[8])\n",
    "    \n",
    "    #FC 2\n",
    "    x = relu.(w[9]* x .+ w[10])\n",
    "    \n",
    "    #OUTPUT\n",
    "    return w[11]* x .+ w[12]\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#DimensionMismatch(\"((1024, 103968), (968, 120), (1024, 120))\")\n",
    "\n",
    "wcnn=map(Atype, [ 0.1*randn(5,5,1,8),  zeros(1,1,8,1), \n",
    "        0.1*randn(5,5,8,8),  zeros(1,1,8,1),\n",
    "        0.1*randn(3,3,8,8),  zeros(1,1,8,1), #103968\n",
    "        0.1*randn(1024,968),  zeros(1024,1),\n",
    "        0.1*randn(1024,1024),  zeros(1024,1), # add PCA Layer parameters later\n",
    "        0.1*randn(48,1024), zeros(48,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN CNN Function\n",
    "\n",
    "function train!(w, data; lr=.01)\n",
    "    for (x,y) in data\n",
    "        println(\"sqr error loss\")\n",
    "        print(loss(w,x,y))\n",
    "        println(\"Huber Loss\")\n",
    "        #print(huber_loss(w,x,y))\n",
    "        dw = lossgradient(w, x, y)\n",
    "        println(size(dw))\n",
    "        for i in 1:length(w) # Loop  over W and B\n",
    "           @time print(w[i] -= lr * dw[i])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN\n",
    "@time cnnmodels = [ copy(train!(wcnn, dtrn)) for epoch=1:5 ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Loss\n",
    "#@time trncnnloss = [mean(abs2,ytrn-predict(w,xtrn)) for w in cnnmodels ]; \n",
    "#@time tstcnnloss = [ mean(abs2,ytst-predict(w,xtst)) for w in cnnmodels ]; \n",
    "\n",
    "trncnnloss=0\n",
    "tstcnnloss =0\n",
    "c=1\n",
    "trncnnlosses= []\n",
    "@time for w in cnnmodels\n",
    "    w= map(Atype, w)\n",
    "    for (x,y) in dtrn\n",
    "        #trncnnloss =+ mean(abs2,y-predict(wcnn,x))\n",
    "        trncnnloss =+ loss(w,x,y)\n",
    "        c+=1\n",
    "    end\n",
    "    push!(trncnnlosses, trncnnloss) #trncnnloss/c\n",
    "end\n",
    "    \n",
    "    \n",
    "#Testing Set   \n",
    "#for (x,y) in dtst\n",
    "    #tstcnnloss =+ loss(wcnn,x,y)\n",
    "#end\n",
    "\n",
    "print(trncnnlosses)\n",
    "#print(tstcnnloss/c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Loss\n",
    "\n",
    "plot( [trncnnlosses],ylim=(.000,.010),labels=[ :trncnnlosses ],xlabel=\"Epochs\",ylabel=\"Loss\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Accuracy\n",
    "\n",
    "#trnAcc= accuracy(wcnn,dtrn,predict)\n",
    "#tstAcc=accuracy(wcnn,dtst,predict)\n",
    "\n",
    "#trnAcc=0\n",
    "#tstAcc =0\n",
    "#c=1\n",
    "\n",
    "#for (x,y) in dtrn\n",
    "   # y= convert(Array{Float32,2},y)\n",
    "   # x= convert(Array{Float32,2},x)\n",
    "   # trnAcc =+ accuracy(predict(wcnn,x),y)\n",
    "    #c+=1\n",
    "#end\n",
    "\n",
    "#for (x,y) in dtst\n",
    "#    y= convert(Array{Float32,2},y)\n",
    "#    tstAcc = + accuracy(predict(wcnn,x),y) \n",
    "#end\n",
    "\n",
    "#print(trnAcc/c)\n",
    "#print(tstAcc/c)\n",
    "\n",
    "#print(trnAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
